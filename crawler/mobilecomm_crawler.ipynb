{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd044b5a777b7624e45e2527e4751e65d23935e9f9a280750eed838ca082febb7b4",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from google.cloud import language_v1\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from crawler_model import Ptt\n",
    "\n",
    "ua = UserAgent()\n",
    "fakeua = ua.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "with open('phone_catalog.json', 'r') as fp:\n",
    "    phone_dict = json.load(fp)"
   ]
  },
  {
   "source": [
    "# phone_list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phones():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_Android_smartphones\"\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(\"table\", class_=\"wikitable\")\n",
    "    rows = []\n",
    "    for i in tables:\n",
    "        rows.extend(i.select(\"tbody tr th\"))\n",
    "\n",
    "    phones = [a.text.partition(\"(\")[0].strip() for a in rows]\n",
    "    phones = [ p for p in phones if len(p.split()) > 1]\n",
    "\n",
    "    brands = set()\n",
    "    for p in phones:\n",
    "        brands.add(p.split(\" \")[0])\n",
    "    brands = list(brands)\n",
    "    brands = sorted(brands)\n",
    "    for b in range(len(brands)):\n",
    "        if brands[b] == \"Asus\":\n",
    "            brands = brands[b:]\n",
    "            break\n",
    "\n",
    "    phone_list = []\n",
    "    for b in brands:\n",
    "        if b == \"Samsung\":\n",
    "            for p in phones:\n",
    "                if p.split(\" \")[0] == b:\n",
    "                    if \"/\" in p:\n",
    "                        p_lst = p.split(\"/\")\n",
    "                        for series in p_lst[1:]:\n",
    "                            sub_p = p_lst[0].replace(\"5G\", \"\").strip()\n",
    "                            if series == \"+\":\n",
    "                                phone = sub_p + series\n",
    "                            else:\n",
    "                                phone = sub_p + \" \" + series\n",
    "                            if len(phone) > 0:\n",
    "                                phone_list.append(phone)\n",
    "                        phone_list.append(sub_p)\n",
    "                    else:\n",
    "                        phone = p.replace(\"5G\", \"\").strip()\n",
    "                        if len(phone) > 0:\n",
    "                            phone_list.append(phone)\n",
    "        elif b == \"POCO\":\n",
    "            for p in phones:\n",
    "                if p.split(\" \")[0] == b:\n",
    "                    phone = p.replace(\"5G\", \"\").strip()\n",
    "                    if len(phone) > 0:\n",
    "                        phone_list.append(phone)\n",
    "\n",
    "        elif b == \"Pixel\":\n",
    "            for p in phones:\n",
    "                if p.split(\" \")[0] == b:\n",
    "                    phone = p.replace(\"5G\", \"\").strip()\n",
    "                    if len(phone) > 0:\n",
    "                        phone_list.append(phone)\n",
    "        else:\n",
    "            for p in phones:\n",
    "                if p.split(\" \")[0] == b:\n",
    "                    if \"/\" in p:\n",
    "                        p_lst = p.split(\"/\")\n",
    "                        for series in p_lst[1:]:\n",
    "                            sub_p = p_lst[0].replace(\"5G\", \"\").strip()\n",
    "                            if series == \"+\":\n",
    "                                phone = sub_p + series\n",
    "                            else:\n",
    "                                phone = sub_p + \" \" + series\n",
    "                            if len(phone) > 0:\n",
    "                                phone_list.append(phone)\n",
    "                        phone_list.append(sub_p)\n",
    "                    else:\n",
    "                        phone = p.replace(\"5G\", \"\").strip()\n",
    "                        if len(phone) > 0:\n",
    "                            phone_list.append(phone)\n",
    "                        phone_list.append(phone)\n",
    "    phone_list.append(\"Asus ROG Phone 2\")\n",
    "    extend = [\"Note 20 Ultra\", \"S20 Ultra\", \"S21 Ultra\", \"S20+\", \"S21+\", \"S20\", \"S21\"]\n",
    "    for s in extend:\n",
    "        phone_list.append(s)\n",
    "\n",
    "    url = \"https://www.theiphonewiki.com/wiki/List_of_iPhones\"\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"div\", id=\"toc\")\n",
    "    iphones = []\n",
    "    for span in table.select(\"ul li span\"):\n",
    "        if \"iPhone\" in str(span):\n",
    "            if (\"SE\" in str(span)) and (\"1\" in str(span)):\n",
    "                iphones.append(\"iPhone SE\")\n",
    "            elif (\"SE\" in str(span)) and (\"2\" in str(span)):\n",
    "                iphones.append(\"iPhone SE2\")\n",
    "            else:\n",
    "                iphones.append(span.text)\n",
    "    iphones.remove(\"iPhone\")\n",
    "    phone_list.extend(iphones)\n",
    "    phone_set = set()\n",
    "    for p in phone_list:\n",
    "        phone_set.add(p)\n",
    "    phone_list = sorted(list(phone_set), key=lambda x: len(x), reverse=True)\n",
    "    phone_list.remove(\"Asus ROG Phone II\")\n",
    "    return phone_list"
   ]
  },
  {
   "source": [
    "# crawl PTT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_page(url):\n",
    "    ua = UserAgent()\n",
    "    fakeua = ua.random\n",
    "    headers = {\"Origin\": \"https://www.ptt.cc\",\n",
    "            \"Referer\": \"https://fonts.googleapis.com/\",\n",
    "            \"sec-ch-ua-mobile\": \"?0\",\n",
    "            \"User-Agent\": fakeua}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    previous = soup.find_all(\"a\", class_=\"btn wide\")[0][\"href\"]\n",
    "    previous_page_num = int(re.findall(r\"\\d+\", previous)[0])\n",
    "    return previous_page_num\n",
    "last_page = get_last_page(\"https://www.ptt.cc/bbs/MobileComm/search?page=1&q=%E5%BF%83%E5%BE%97\")\n",
    "last_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_analyze_sentiment(text_content):\n",
    "    \"\"\"\n",
    "    Analyzing Sentiment in a String\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze\n",
    "    \"\"\"\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= os.path.join(os.path.expanduser(\"~\"), \"smartphone-smartprice-key.json\")\n",
    "\n",
    "    post = {}\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # text_content = 'I am so happy and joyful.'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    document = {\"content\": text_content, \"type_\": type_}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = language_v1.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_sentiment(request = {'document': document, 'encoding_type': encoding_type})\n",
    "    # Get overall sentiment of the input document\n",
    "    doc = {}\n",
    "    doc[\"score\"] = response.document_sentiment.score\n",
    "    \n",
    "    doc[\"magnitude\"] = response.document_sentiment.magnitude\n",
    "\n",
    "    # Get sentiment for all sentences in the document\n",
    "    sentences = []\n",
    "    for sentence in response.sentences:\n",
    "        # if abs(sentence.sentiment.score) >= 0.5 and sentence.sentiment.magnitude >= 0.5:\n",
    "        d = {}\n",
    "        d[\"content\"] = sentence.text.content.replace(\".\", \"\").replace(\"。\", \"\")\n",
    "        d[\"score\"] = sentence.sentiment.score\n",
    "        d[\"magnitude\"] = sentence.sentiment.magnitude\n",
    "        sentences.append(d)\n",
    "    \n",
    "    return doc, sentences\n",
    "\n",
    "def crawl_comm(links):\n",
    "    for link in links:\n",
    "        url = \"https://www.ptt.cc\" + link[1]\n",
    "        # GET request from url and parse via BeautifulSoup\n",
    "        ua = UserAgent()\n",
    "        fakeua = ua.random\n",
    "        headers = {\"Origin\": \"https://www.ptt.cc\",\n",
    "                \"Referer\": \"https://fonts.googleapis.com/\",\n",
    "                \"sec-ch-ua-mobile\": \"?0\",\n",
    "                \"User-Agent\": fakeua}\n",
    "        resp = requests.get(url, headers=headers)\n",
    "        if \"200\" in str(resp):\n",
    "            soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "            main = soup.find(\"div\", id=\"main-content\")\n",
    "            print(main.text)\n",
    "            # keywords = [\"優點\", \"缺點\", \"照相\", \"電池\", \"續航\"]\n",
    "            if \"※ 引述\" in str(main):   \n",
    "                body = str(main).split('※ 引述')[0].split('</span></div>')[-1].replace(\" \",\"\").replace(\"\\n\", \"。\")\n",
    "                body = BeautifulSoup(body).text\n",
    "            else:\n",
    "                body = str(main).split('--')[0].split('</span></div>')[-1].replace(\" \",\"\").replace(\"\\n\", \"。\")\n",
    "                body = BeautifulSoup(body).text\n",
    "        doc, sentences = sample_analyze_sentiment(body)\n",
    "        d = {\"title\": link[0], \"link\": link[1], \"doc\": doc, \"sentences\": sentences}\n",
    "        print(d)\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "data = []\n",
    "error_links = []\n",
    "for page in range(1, 2):\n",
    "\n",
    "    ua = UserAgent()\n",
    "    fakeua = ua.random\n",
    "    headers = {\"Origin\": \"https://www.ptt.cc\",\n",
    "            \"Referer\": \"https://fonts.googleapis.com/\",\n",
    "            \"sec-ch-ua-mobile\": \"?0\",\n",
    "            \"User-Agent\": fakeua}\n",
    "\n",
    "    url = \"https://www.ptt.cc/bbs/MobileComm/search?page={}&q=%E5%BF%83%E5%BE%97\".format(page)\n",
    "    print(url)\n",
    "    phone_list = get_phones()\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    index_soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    keywords = [\"換\", \"vs\", \"v.s\", \"vs.\", \"v.s.\"]\n",
    "    title = index_soup.findAll(\"div\", class_=\"title\")\n",
    "\n",
    "    links = []\n",
    "    for t in title:\n",
    "        if any(keyword in t.text for keyword in keywords):\n",
    "            pass\n",
    "        else:\n",
    "            for p in phone_list:\n",
    "                if p.replace(\" \", \"\").lower() in t.text.replace(\" \", \"\").lower():\n",
    "                    print(p, t)\n",
    "                    links.append( (t.text, \"https://www.ptt.cc\" + t.find(\"a\")[\"href\"]) )\n",
    "                    break\n",
    "                    break\n",
    "        \n",
    "\n",
    "    crawl_comm(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "print(len(data))\n",
    "data[0]"
   ]
  },
  {
   "source": [
    "# Sentiment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentifish import Sentiment\n",
    "text='''2020/02自美國雅馬遜購入\n",
    "昨天發現電池膨脹了\n",
    "爬了一下板上資訊\n",
    "應該可以更換保固區域後以延長保固1年為由\n",
    "更換（整）新機\n",
    "\n",
    "但也看到線上服務看得是一種運\n",
    "不是大好就是大壞\n",
    "不巧小弟抽到壞的那邊\n",
    "客服堅持不是官網買的無法處理\n",
    "也沒有換保固區域的處理\n",
    "另外也說電池膨脹不在延長保固之範圍\n",
    "（但電量消耗大是可以的）\n",
    "\n",
    "總之就是叫我自己去找雅馬遜處理\n",
    "\n",
    "我想這樣的客服\n",
    "我大概不會再買pixel了吧'''\n",
    "obj=Sentiment(text)\n",
    "polarity = obj.analyze( )\n",
    "polarity"
   ]
  },
  {
   "source": [
    "# mobile01"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'user-agent': fakeua,\n",
    "    'x-api-source': 'pc',\n",
    "    'referer': \"https://shopee.tw/product/354450050/8754002931\"\n",
    "    }\n",
    "r = requests.get(\"https://shopee.tw/product/354450050/8754002931\", headers=headers)\n",
    "print(r)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "print(soup.prettfy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "headers = {\n",
    "    'origin': 'https://www.mobile01.com',\n",
    "    'referer': \"https://www.mobile01.com/\",\n",
    "    'sec-ch-ua': \"Not A;Brand;v=99, Chromium;v=90, Google Chrome;v=90\",\n",
    "    'user-agent': fakeua,\n",
    "    }\n",
    "s.headers = headers\n",
    "r = s.get(\"https://www.mobile01.com/newslist.php?type=1&c=16&date=2021\")\n",
    "print(r)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "a = soup.find(\"a\", class_=\"c-articleCard\")\n",
    "links = [ d[\"href\"] for d in a ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "headers = {\n",
    "    'origin': 'https://www.mobile01.com',\n",
    "    'referer': \"https://www.mobile01.com/\",\n",
    "    'user-agent': fakeua,\n",
    "    }\n",
    "s.headers = headers\n",
    "r = s.get(\"https://www.mobile01.com/topicdetail.php?f=754&t=6385086\")\n",
    "print(r)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "# a = soup.find(\"a\", class_=\"c-articleCard\")\n",
    "# links = [ d[\"href\"] for d in a ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "url = \"https://www.mobile01.com/newslist.php?type=1&c=16&date=2021\"\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "pageSource = driver.page_source\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(pageSource, \"html.parser\")\n",
    "a = soup.findAll(\"a\", class_=\"c-articleCard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sony Xperia 10 III Sony Xperia 10 III 試用｜最高防水和大電量 讓你安心在手機上人與人連結\nAsus ZenFone 8 ASUS ZenFone 8 / 8 Flip體驗｜翻轉依舊、也玩輕巧！\nOppo Reno5 OPPO Reno5 Z試用 顏值輕巧兼具的5G中階\nPOCO X3 Pro POCO X3 Pro試用/ 大電量跟有CP值就是賣點\nPOCO F3 POCO F3試用/ 萬元買到Snapdragon 870高性能\nRealme GT realme GT體驗｜效能特化、最便宜S888旗艦！\nVivo X60 Pro vivo X60 Pro 評測｜攝錄「穩」中求趣、效能直逼旗艦！\nAsus ROG Phone 5 ASUS ROG Phone 5 Ultimate體驗｜回歸絢爛設計、機型再進化！\nOppo Reno5 OPPO Reno 5 雙機體驗｜同門不同派 效能是最大差異！\nSamsung Galaxy S21 Ultra Snapdragon 888版Galaxy S21 Ultra玩遊戲紀錄 不是每款都有意外\nSamsung Galaxy S21 三星Galaxy S21/S20各種測試 拍照/螢幕/散熱差異一次看！\nSamsung Galaxy S21 Ultra 三星Galaxy S21 Ultra揭曉：百倍變焦進化、重點是軟體應用！\nOppo A73 OPPO A73 5G試用：輕鬆入手價格 輕鬆拍好人像\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "keywords = [\"換\", \"vs\", \"v.s\", \"vs.\", \"v.s.\", \"跳\", \"比\", \"較\", \"戰\"]\n",
    "extend = [\"Note 20 Ultra\", \"S20 Ultra\", \"S21 Ultra\", \"S20+\", \"S21+\", \"S20\", \"S21\"]\n",
    "phone_list = get_phones()\n",
    "for d in a:\n",
    "    t = d.find(\"div\", class_=\"l-articleCardDesc\").text.strip()\n",
    "    if any(keyword in t for keyword in keywords):\n",
    "        pass\n",
    "    else:\n",
    "        for p in phone_list:\n",
    "            if p.replace(\" \", \"\").lower() in t.replace(\" \", \"\").lower():\n",
    "                if p in extend:\n",
    "                    p = \"Samsung Galaxy \" + p\n",
    "                print(p, t)\n",
    "                links.append( (p, t, \"https://www.mobile01.com/\" + d[\"href\"]) )\n",
    "                break\n",
    "                break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Sony Xperia 10 III',\n",
       "  'Sony Xperia 10 III 試用｜最高防水和大電量 讓你安心在手機上人與人連結',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=569&t=6374069'),\n",
       " ('Asus ZenFone 8',\n",
       "  'ASUS ZenFone 8 / 8 Flip體驗｜翻轉依舊、也玩輕巧！',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=588&t=6363391'),\n",
       " ('Oppo Reno5',\n",
       "  'OPPO Reno5 Z試用 顏值輕巧兼具的5G中階',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=689&t=6357976'),\n",
       " ('POCO X3 Pro',\n",
       "  'POCO X3 Pro試用/ 大電量跟有CP值就是賣點',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=634&t=6352979'),\n",
       " ('POCO F3',\n",
       "  'POCO F3試用/ 萬元買到Snapdragon 870高性能',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=634&t=6350896'),\n",
       " ('Realme GT',\n",
       "  'realme GT體驗｜效能特化、最便宜S888旗艦！',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=789&t=6349965'),\n",
       " ('Vivo X60 Pro',\n",
       "  'vivo X60 Pro 評測｜攝錄「穩」中求趣、效能直逼旗艦！',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=754&t=6334883'),\n",
       " ('Asus ROG Phone 5',\n",
       "  'ASUS ROG Phone 5 Ultimate體驗｜回歸絢爛設計、機型再進化！',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=588&t=6321569'),\n",
       " ('Oppo Reno5',\n",
       "  'OPPO Reno 5 雙機體驗｜同門不同派 效能是最大差異！',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=689&t=6315275'),\n",
       " ('Samsung Galaxy S21 Ultra',\n",
       "  'Snapdragon 888版Galaxy S21 Ultra玩遊戲紀錄 不是每款都有意外',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=568&t=6296489'),\n",
       " ('Samsung Galaxy S21',\n",
       "  '三星Galaxy S21/S20各種測試 拍照/螢幕/散熱差異一次看！',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=568&t=6291659'),\n",
       " ('Samsung Galaxy S21 Ultra',\n",
       "  '三星Galaxy S21 Ultra揭曉：百倍變焦進化、重點是軟體應用！',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=568&t=6283135'),\n",
       " ('Oppo A73',\n",
       "  'OPPO A73 5G試用：輕鬆入手價格 輕鬆拍好人像',\n",
       "  'https://www.mobile01.com/topicdetail.php?f=689&t=6276010')]"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Driver [/Users/addie_tyc/.wdm/drivers/chromedriver/mac64/91.0.4472.19/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for link in links[:1]:\n",
    "    url = link[2]\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    pageSource = driver.page_source\n",
    "    soup = BeautifulSoup(pageSource, \"html.parser\")\n",
    "    created_at = soup.find(\"span\", class_=\"o-fNotes o-fSubMini\").text\n",
    "    created_at = datetime.strptime(created_at, '%Y-%m-%d %H:%M')\n",
    "    div = soup.find(\"div\", itemprop=\"articleBody\")\n",
    "    body = div.text\n",
    "    doc, sentences = sample_analyze_sentiment(body.replace(\"\\n\", \"。\"))\n",
    "    driver.close()\n",
    "    d = {\"title\": link[0], \"arc_title\": link[1], \"link\": link[2], \"doc\": doc, \"sentences\": sentences, \"body\": body, \"created_at\": created_at}\n",
    "    data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}